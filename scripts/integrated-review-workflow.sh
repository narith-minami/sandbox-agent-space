#!/usr/bin/env bash
# integrated-review-workflow.sh
# OpenCodeå®Ÿè£… â†’ AI Code Review â†’ åˆ†æ â†’ ä¿®æ­£åå¾© â†’ PRä½œæˆã®çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
#
# å‰ææ¡ä»¶:
#   - PLAN_TEXT ãŒç’°å¢ƒå¤‰æ•°ã§æ¸¡ã•ã‚Œã¦ã„ã‚‹ã“ã¨ï¼ˆå¿…é ˆï¼‰
#   - .env.local ã« APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨
#   - Vercel Sandbox SnapshotãŒä½œæˆæ¸ˆã¿ã§ã‚ã‚‹ã“ã¨
#   - GitHub CLI (gh) ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã§ã‚ã‚‹ã“ã¨
#
# ä½¿ã„æ–¹:
#   PLAN_TEXT="ã‚¿ã‚¹ã‚¯å†…å®¹" SNAPSHOT_ID=snap_xxx ./scripts/integrated-review-workflow.sh

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"

# ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã§ create-base-snapshot ç”±æ¥ã®å ´åˆã¯ clone ãŒ repo/ ã«ã‚ã‚‹
if [[ -d "$SCRIPT_DIR/repo" ]]; then
  cd "$SCRIPT_DIR/repo"
  PROJECT_ROOT="$SCRIPT_DIR/repo"
fi

# -----------------------
# è¨­å®š
# -----------------------
# æœªæŒ‡å®šæ™‚ã¯ã‚«ãƒ¬ãƒ³ãƒˆï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆï¼‰ã€‚frontend/ ãŒãªã„ Next.js ç­‰ã«å¯¾å¿œ
FRONT_DIR="${FRONT_DIR:-.}"
# ãƒ›ã‚¹ãƒˆãŒ frontend ã‚’æ¸¡ã—ã¦ã‚‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒç„¡ã‘ã‚Œã°ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ä½¿ã†
if [[ ! -d "$FRONT_DIR" ]]; then
  FRONT_DIR="."
fi
REVIEW_DIR="${REVIEW_DIR:-./ai-review-results}"
MAX_REVIEW_ITERATIONS="${MAX_REVIEW_ITERATIONS:-3}"
CURRENT_ITERATION=0

REPO_SLUG="${REPO_SLUG:-lbose-corp/yamachiku}"
BASE_BRANCH="${BASE_BRANCH:-staging}"
NEW_BRANCH="feature/ai-review-$(date +%Y%m%d-%H%M%S)"

log() { echo "[$(date +'%H:%M:%S')] $*"; }
die() { log "âŒ ERROR: $*" >&2; exit 1; }

# -----------------------
# .env.local èª­ã¿è¾¼ã¿
# -----------------------
# ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã§ Gist ã‹ã‚‰ run.sh ã¨ã—ã¦å®Ÿè¡Œã•ã‚Œã‚‹å ´åˆã¯ SCRIPT_DIR ã«ãƒ›ã‚¹ãƒˆãŒ .env.local ã‚’é…ç½®ã™ã‚‹
if [[ -f "$SCRIPT_DIR/.env.local" ]]; then
  ENV_FILE="$SCRIPT_DIR/.env.local"
elif [[ -f "$PROJECT_ROOT/.env.local" ]]; then
  ENV_FILE="$PROJECT_ROOT/.env.local"
else
  ENV_FILE="$PROJECT_ROOT/.env.local"
fi

if [[ ! -f "$ENV_FILE" ]]; then
  cat << EOF
âŒ .env.local not found!

Create it with:
  cd $PROJECT_ROOT
  ./scripts/setup-env.sh

Or manually create: $PROJECT_ROOT/.env.local
with at least one AI provider API key:
  - ANTHROPIC_API_KEY (recommended)
  - OPENAI_API_KEY
  - GEMINI_API_KEY
EOF
  exit 1
fi

log "Loading environment from: $ENV_FILE"

# .env.local ã‚’èª­ã¿è¾¼ã¿ï¼ˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼‰
set -a
source "$ENV_FILE"
set +a

# å¿…é ˆãƒã‚§ãƒƒã‚¯
if [[ -z "${ANTHROPIC_API_KEY:-}${OPENAI_API_KEY:-}${GEMINI_API_KEY:-}" ]]; then
  die "No AI provider API key found in .env.local. Set ANTHROPIC_API_KEY, OPENAI_API_KEY, or GEMINI_API_KEY"
fi

if [[ -z "${GITHUB_TOKEN:-}" ]]; then
  die "GITHUB_TOKEN not found in .env.local. Required for PR creation."
fi

: "${PLAN_TEXT:?PLAN_TEXT is required}"

# ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è‡ªå‹•æ¤œå‡º
if [[ -n "${ANTHROPIC_API_KEY:-}" ]]; then
  AI_PROVIDER="anthropic"
  AI_MODEL="claude-3-haiku-20240307"
  log "Using Anthropic Claude Haiku"
elif [[ -n "${OPENAI_API_KEY:-}" ]]; then
  AI_PROVIDER="openai"
  AI_MODEL="gpt-4o-mini"
  log "Using OpenAI GPT-4o-mini"
elif [[ -n "${GEMINI_API_KEY:-}" ]]; then
  AI_PROVIDER="gemini"
  AI_MODEL="gemini-2.0-flash-exp"
  log "Using Google Gemini Flash"
fi

# -----------------------
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# -----------------------
# jq ãŒç„¡ã„ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã§ã‚‚å‹•ãã‚ˆã†ã« Node ã§ JSON ã‚’æ‰±ã†
json_get() {
  local json="$1" path="$2" default="${3:-}"
  if command -v jq &>/dev/null; then
    echo "$json" | jq -r "${path} // \"$default\"" 2>/dev/null || echo "$default"
  else
    node -e "
      try {
        var j = JSON.parse(process.argv[1]);
        var p = (process.argv[2] || '').replace(/^\\./, '').split('.');
        var v = j;
        for (var i = 0; i < p.length && v != null; i++) v = v[p[i]];
        console.log(v !== undefined && v !== null ? String(v) : process.argv[3]);
      } catch (e) { console.log(process.argv[3]); }
    " "$json" "$path" "$default" 2>/dev/null || echo "$default"
  fi
}
json_pretty() {
  local json="$1"
  if command -v jq &>/dev/null; then
    echo "$json" | jq '.' 2>/dev/null || echo "$json"
  else
    node -e "try { console.log(JSON.stringify(JSON.parse(process.argv[1]), null, 2)); } catch(e) { console.log(process.argv[1]); }" "$json" 2>/dev/null || echo "$json"
  fi
}

run_opencode_implementation() {
  local task_description="$1"
  local iteration_note="${2:-}"
  
  log "Running OpenCode implementation..."
  pushd "$FRONT_DIR" >/dev/null
  
  opencode run "$task_description

$iteration_note

Project:
- Next.js app (or frontend app in this directory)
- Use existing patterns and conventions
- Dependencies are already installed (node_modules exists)

Rules:
- Do not modify files outside this directory
- Keep changes minimal and reviewable
- Do NOT run 'npm ci' or 'npm install' (already done)

Implementation Steps:
1. Read and understand the requirements
2. Implement the functionality
3. Run quality gates (detailed below)
4. Self-review your changes

CRITICAL - Quality Gates (MUST PASS):
After implementation, you MUST run these checks IN ORDER and fix all errors:

1. Format check and auto-fix:
   \`\`\`bash
   npx biome check --write .
   \`\`\`

2. Type check (MUST pass with 0 errors):
   \`\`\`bash
   npm run tsc
   \`\`\`

3. Lint check (MUST pass with 0 errors):
   \`\`\`bash
   npm run lint
   \`\`\`

If ANY check fails:
- Read the error messages carefully
- Fix the root cause (not just symptoms)
- Re-run ALL checks from step 1
- Repeat until ALL checks pass

Only after ALL checks pass with 0 errors, provide a summary of changes."
  
  popd >/dev/null
}

run_ai_review() {
  local review_type="${1:-comprehensive}"
  local output_suffix="${2:-}"
  
  mkdir -p "$REVIEW_DIR"
  
  log "Running ${review_type} review..."
  
  local log_file="${REVIEW_DIR}/review-${review_type}${output_suffix}.log"
  
  # CLI ã¯ .ai-review-config.json ã¾ãŸã¯ .ai-code-review/config.yaml ã‚’å‚ç…§ã€‚--provider/--model ã¯éå¯¾å¿œã®ãŸã‚æ¸¡ã•ãªã„
  npx @bobmatnyc/ai-code-review "$FRONT_DIR" \
    --type "$review_type" \
    --output json \
    2>&1 | tee "$log_file" || true
  
  # ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
  local review_files=$(find "$FRONT_DIR/ai-review-docs" -name "*.json" -o -name "*.md" 2>/dev/null || true)
  
  if [[ -n "$review_files" ]]; then
    # ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’çµ±åˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼
    mkdir -p "$REVIEW_DIR/docs"
    cp -r "$FRONT_DIR/ai-review-docs"/* "$REVIEW_DIR/docs/" 2>/dev/null || true
    log "âœ“ Review results saved to $REVIEW_DIR/docs"
  else
    log "âš ï¸  No review output found for ${review_type}"
  fi
}

analyze_review_results() {
  local review_dir="$1"
  
  log "Analyzing review results..."
  
  # ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
  if [[ ! -d "$review_dir/docs" ]] || [[ -z "$(ls -A "$review_dir/docs" 2>/dev/null)" ]]; then
    log "âš ï¸  No review files found in $review_dir/docs"
    echo '{"totalIssues":0,"bySeverity":{"critical":0,"high":0,"medium":0,"low":0},"needsFix":false,"criticalIssues":[]}'
    return
  fi
  
  # Node.js ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§è§£æ
  node "$SCRIPT_DIR/review-tools/analyze-review.js" "$review_dir/docs" 2>/dev/null || echo '{"totalIssues":0,"bySeverity":{"critical":0,"high":0,"medium":0,"low":0},"needsFix":false,"criticalIssues":[]}'
}

# -----------------------
# Step 1-6: æ—¢å­˜ã®æº–å‚™å‡¦ç†ï¼ˆçœç•¥å¯èƒ½ï¼‰
# -----------------------
log "==================================================================="
log "Starting Integrated AI Code Review Workflow"
log "==================================================================="
log "Repository: $REPO_SLUG"
log "Base branch: $BASE_BRANCH"
log "New branch: $NEW_BRANCH"
log "AI Provider: $AI_PROVIDER ($AI_MODEL)"
log "Max iterations: $MAX_REVIEW_ITERATIONS"
log "==================================================================="

# Git ãƒ–ãƒ©ãƒ³ãƒä½œæˆ
if [[ -d .git ]]; then
  git checkout -b "$NEW_BRANCH"
  log "âœ“ Created branch: $NEW_BRANCH"
fi

# -----------------------
# Step 7: OpenCodeåˆæœŸå®Ÿè£…
# -----------------------
log "Step 7/11: Running OpenCode for initial implementation..."

run_opencode_implementation "$PLAN_TEXT"

log "âœ“ OpenCode initial implementation completed"

# -----------------------
# Step 8: AIãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œï¼ˆä¸¦åˆ—ï¼‰
# -----------------------
log "Step 8/11: Running AI Code Review (multiple types in parallel)..."

# å‰å›ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’ã‚¯ãƒªã‚¢
rm -rf "$REVIEW_DIR"
rm -rf "$FRONT_DIR/ai-review-docs"
mkdir -p "$REVIEW_DIR"

# è¤‡æ•°ã‚¿ã‚¤ãƒ—ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä¸¦åˆ—å®Ÿè¡Œ
run_ai_review "security" &
SECURITY_PID=$!
run_ai_review "performance" &
PERFORMANCE_PID=$!
run_ai_review "comprehensive" &
COMPREHENSIVE_PID=$!

# å…¨ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†ã‚’å¾…æ©Ÿ
wait $SECURITY_PID
wait $PERFORMANCE_PID
wait $COMPREHENSIVE_PID

log "âœ“ All reviews completed"

# -----------------------
# Step 9: ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœåˆ†æ
# -----------------------
log "Step 9/11: Analyzing review results..."

ANALYSIS_JSON=$(analyze_review_results "$REVIEW_DIR")
json_pretty "$ANALYSIS_JSON" > "$REVIEW_DIR/analysis.json"

# åˆ†æçµæœã‹ã‚‰åˆ¤å®š
NEEDS_FIX=$(json_get "$ANALYSIS_JSON" ".needsFix" "false")
CRITICAL_COUNT=$(json_get "$ANALYSIS_JSON" ".bySeverity.critical" "0")
HIGH_COUNT=$(json_get "$ANALYSIS_JSON" ".bySeverity.high" "0")
MEDIUM_COUNT=$(json_get "$ANALYSIS_JSON" ".bySeverity.medium" "0")
LOW_COUNT=$(json_get "$ANALYSIS_JSON" ".bySeverity.low" "0")
TOTAL_ISSUES=$(json_get "$ANALYSIS_JSON" ".totalIssues" "0")

log "Review Analysis:"
log "  - Total issues: $TOTAL_ISSUES"
log "  - Critical: $CRITICAL_COUNT"
log "  - High: $HIGH_COUNT"
log "  - Medium: $MEDIUM_COUNT"
log "  - Low: $LOW_COUNT"

# -----------------------
# Step 10: ä¿®æ­£ãŒå¿…è¦ãªã‚‰åå¾©
# -----------------------
while [[ "$NEEDS_FIX" == "true" ]] && [[ $CURRENT_ITERATION -lt $MAX_REVIEW_ITERATIONS ]]; do
  CURRENT_ITERATION=$((CURRENT_ITERATION + 1))
  
  log "Step 10/11: Issues found. Running OpenCode fix iteration $CURRENT_ITERATION..."
  
  # ä¿®æ­£æŒ‡ç¤ºã‚’èª­ã¿è¾¼ã¿
  if [[ -f "$REVIEW_DIR/docs/fix-instructions.txt" ]]; then
    FIX_INSTRUCTIONS=$(cat "$REVIEW_DIR/docs/fix-instructions.txt")
  else
    log "âš ï¸  No fix-instructions.txt found, skipping fix iteration"
    break
  fi
  
  # OpenCodeã§ä¿®æ­£å®Ÿè¡Œ
  ITERATION_NOTE="ITERATION $CURRENT_ITERATION - FIXING PREVIOUS ISSUES:

The previous implementation had the following critical/high severity issues:

$FIX_INSTRUCTIONS

Please fix ALL these issues while:
- Maintaining the original functionality
- Following the same coding patterns
- Ensuring quality gates still pass
- Providing clear explanations of fixes"

  run_opencode_implementation "$PLAN_TEXT" "$ITERATION_NOTE"
  
  log "âœ“ OpenCode fix iteration $CURRENT_ITERATION completed"
  
  # å†åº¦ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œ
  log "Re-running comprehensive review..."
  rm -rf "$FRONT_DIR/ai-review-docs"
  rm -rf "$REVIEW_DIR/docs"
  
  run_ai_review "comprehensive" "-iteration${CURRENT_ITERATION}"
  
  # å†åˆ†æ
  ANALYSIS_JSON=$(analyze_review_results "$REVIEW_DIR")
  json_pretty "$ANALYSIS_JSON" > "$REVIEW_DIR/analysis-iteration${CURRENT_ITERATION}.json"
  
  NEEDS_FIX=$(json_get "$ANALYSIS_JSON" ".needsFix" "false")
  CRITICAL_COUNT=$(json_get "$ANALYSIS_JSON" ".bySeverity.critical" "0")
  HIGH_COUNT=$(json_get "$ANALYSIS_JSON" ".bySeverity.high" "0")
  
  log "Re-review Analysis (Iteration $CURRENT_ITERATION):"
  log "  - Critical: $CRITICAL_COUNT"
  log "  - High: $HIGH_COUNT"
  
  if [[ "$NEEDS_FIX" == "false" ]]; then
    log "âœ… All critical/high issues resolved!"
    break
  fi
done

# æœ€å¤§åå¾©å›æ•°ã«é”ã—ãŸå ´åˆ
if [[ $CURRENT_ITERATION -ge $MAX_REVIEW_ITERATIONS ]] && [[ "$NEEDS_FIX" == "true" ]]; then
  log "âš ï¸  Maximum iterations ($MAX_REVIEW_ITERATIONS) reached with unresolved issues"
  log "âš ï¸  Manual review required before PR"
fi

# -----------------------
# Step 11: æœ€çµ‚ãƒã‚§ãƒƒã‚¯ & PRä½œæˆ
# -----------------------
log "Step 11/11: Final checks and creating PR..."

# package.json ãŒã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã„ã‚‹ã“ã¨ã‚’ä¿è¨¼ï¼ˆã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã§ cwd ãŒ /vercel/sandbox ã®ã¾ã¾ã®ã¨ãï¼‰
if [[ ! -f "package.json" ]] && [[ -d "$SCRIPT_DIR/repo" ]]; then
  cd "$SCRIPT_DIR/repo" || true
fi

# æœ€çµ‚çš„ãªå“è³ªãƒã‚§ãƒƒã‚¯
log "Running final quality gates..."
pushd "$FRONT_DIR" >/dev/null

# Biome
log "Running Biome..."
if ! npx biome check --write . 2>&1 | tail -5; then
  log "âš ï¸  Biome check had warnings (non-fatal)"
fi

# TypeScript
log "Running TypeScript check..."
if ! npm run tsc 2>&1 | tail -10; then
  die "TypeScript check failed"
fi

# Lint
log "Running Lint..."
if ! npm run lint 2>&1 | tail -10; then
  die "Lint check failed"
fi

popd >/dev/null
log "âœ“ All quality gates passed"

# Gitè¨­å®š
git config user.name "OpenCode Bot"
git config user.email "opencode-bot@users.noreply.github.com"

# ã‚³ãƒŸãƒƒãƒˆ
git add -A
if git diff --cached --quiet; then
  die "No changes detected. Nothing to commit."
fi

# ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
COMMIT_MSG="feat: implement task from plan

Implemented by OpenCode with AI Code Review integration

Quality gates: âœ“ Format âœ“ TypeScript âœ“ Lint
AI Review: $(if [[ "$NEEDS_FIX" == "false" ]]; then echo "âœ“ Passed"; else echo "âš ï¸ Manual review needed"; fi) ($CURRENT_ITERATION iterations)
  - Critical issues: $CRITICAL_COUNT
  - High issues: $HIGH_COUNT
  - Medium issues: $MEDIUM_COUNT
  - Low issues: $LOW_COUNT"

git commit -m "$COMMIT_MSG"
log "âœ“ Changes committed"

# PRå†…å®¹ç”Ÿæˆ
PLAN_SUMMARY=$(echo "$PLAN_TEXT" | head -n 1 | cut -c1-60)
PR_TITLE="feat: ${PLAN_SUMMARY}"

# ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
REVIEW_SUMMARY=$(cat <<EOF
## ğŸ¤– AI Code Review Summary

**Review Iterations:** $CURRENT_ITERATION
**Final Status:** $(if [[ "$NEEDS_FIX" == "false" ]]; then echo "âœ… Approved"; else echo "âš ï¸ Needs Manual Review"; fi)
**AI Provider:** $AI_PROVIDER ($AI_MODEL)

### Issue Breakdown
- ğŸ”´ Critical: $CRITICAL_COUNT
- ğŸŸ  High: $HIGH_COUNT
- ğŸŸ¡ Medium: $MEDIUM_COUNT
- ğŸŸ¢ Low: $LOW_COUNT
- **Total:** $TOTAL_ISSUES

### Review Types Executed
- âœ“ Security Review (authentication, SQL injection, XSS, etc.)
- âœ“ Performance Review (N+1 queries, caching, bundle size)
- âœ“ Comprehensive Review (code quality, best practices, testing)

<details>
<summary>ğŸ“Š Detailed Analysis</summary>

\`\`\`json
$ANALYSIS_JSON
\`\`\`

</details>
EOF
)

PR_BODY="## ğŸ“‹ ã‚¿ã‚¹ã‚¯å†…å®¹

\`\`\`
${PLAN_TEXT}
\`\`\`

## âœ… å®Ÿè£…å®Œäº†

- OpenCodeã«ã‚ˆã‚‹è‡ªå‹•å®Ÿè£…
- AI Code Reviewå®Ÿæ–½ï¼ˆ$CURRENT_ITERATION iterationsï¼‰
- å“è³ªãƒã‚§ãƒƒã‚¯æ¸ˆã¿ (Format / TypeScript / Lint)

$REVIEW_SUMMARY

## ğŸ“ å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«

\`\`\`
$(git diff --name-status "$BASE_BRANCH"..HEAD)
\`\`\`

## ğŸ” ç¢ºèªæ–¹æ³•

\`\`\`bash
git checkout $NEW_BRANCH
cd frontend
npm run build
\`\`\`

---
Generated by Snapshot Workflow v2.0 with AI Code Review Integration
Powered by @bobmatnyc/ai-code-review"

# Push
log "Pushing branch..."
git remote set-url origin "https://${GITHUB_TOKEN}@github.com/${REPO_SLUG}.git"
if ! git push origin "$NEW_BRANCH"; then
  die "Failed to push branch"
fi
log "âœ“ Branch pushed"

# GitHub CLIèªè¨¼
log "Authenticating GitHub CLI..."
echo "$GITHUB_TOKEN" | gh auth login --with-token 2>/dev/null || true

# ãƒªãƒã‚¸ãƒˆãƒªè¨­å®š
log "Setting repository..."
gh repo set-default "$REPO_SLUG" 2>/dev/null || true

# PRä½œæˆ
log "Creating pull request..."
PR_URL=$(gh pr create \
  --repo "$REPO_SLUG" \
  --title "$PR_TITLE" \
  --body "$PR_BODY" \
  --base "$BASE_BRANCH" \
  --head "$NEW_BRANCH" 2>&1)

PR_EXIT_CODE=$?

if [[ $PR_EXIT_CODE -ne 0 ]]; then
  log "âŒ PR creation failed with exit code: $PR_EXIT_CODE"
  log "Error output: $PR_URL"
  die "Failed to create pull request"
fi

log "==================================================================="
log "âœ… PR Created Successfully with AI Review!"
log "==================================================================="
log "PR URL: $PR_URL"
log "Branch: $NEW_BRANCH -> $BASE_BRANCH"
log "Workflow: Snapshot v2.0 with AI Review"
log "Review Iterations: $CURRENT_ITERATION"
log "Final Status: $(if [[ "$NEEDS_FIX" == "false" ]]; then echo "âœ… Approved"; else echo "âš ï¸ Manual Review Needed"; fi)"
log "Total Issues: $TOTAL_ISSUES (Critical: $CRITICAL_COUNT, High: $HIGH_COUNT)"
log "Total time: ${SECONDS}s"
log "==================================================================="

# ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦PRã‚³ãƒ¡ãƒ³ãƒˆã«è¿½åŠ 
if [[ -f "$REVIEW_DIR/analysis.json" ]]; then
  log "Adding review analysis as PR comment..."
  
  COMMENT_BODY="## ğŸ“Š Detailed AI Review Analysis

<details>
<summary>Click to expand full analysis</summary>

\`\`\`json
$(cat "$REVIEW_DIR/analysis.json")
\`\`\`

</details>

### Review Artifacts
- Analysis results: \`$REVIEW_DIR/analysis.json\`
- Review logs: \`$REVIEW_DIR/*.log\`
- Review docs: \`$REVIEW_DIR/docs/\`

### AI Provider
- Provider: $AI_PROVIDER
- Model: $AI_MODEL
- Iterations: $CURRENT_ITERATION"

  gh pr comment "$PR_URL" --body "$COMMENT_BODY" 2>/dev/null || log "âš ï¸  Failed to add PR comment"
fi

echo "$PR_URL"
log "âœ“ Workflow completed successfully"
