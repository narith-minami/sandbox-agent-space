#!/bin/bash
# run-opencode-with-snapshot.sh
# Optimized for snapshot-based workflow with AI Code Review Integration
# 1 task = 1 branch = 1 session
#
# Version: 2.1.0 (AI Review Integration)
#
# å¿…é ˆç’°å¢ƒå¤‰æ•°: 
#   SNAPSHOT_ID, GITHUB_TOKEN, OPENCODE_AUTH_JSON_B64, PLAN_TEXT
#   ANTHROPIC_API_KEY (ã¾ãŸã¯ OPENAI_API_KEY / GEMINI_API_KEY)

set -euo pipefail

# ============================================================
# Snapshot-based OpenCode Workflow with AI Code Review
# Created: 2026-02-04
# Updated: 2026-02-05 (AI Review Integration)
# Version: 2.1.0
# ============================================================

# -----------------------
# Required (Snapshotç‰ˆç‰¹æœ‰)
# -----------------------
: "${SNAPSHOT_ID:?SNAPSHOT_ID is required for snapshot workflow}"
: "${GITHUB_TOKEN:?GITHUB_TOKEN is required}"
: "${OPENCODE_AUTH_JSON_B64:?OPENCODE_AUTH_JSON_B64 is required}"
: "${PLAN_TEXT:?PLAN_TEXT is required}"

# AI Reviewç”¨ï¼ˆã„ãšã‚Œã‹1ã¤å¿…é ˆï¼‰
if [[ -z "${ANTHROPIC_API_KEY:-}${OPENAI_API_KEY:-}${GEMINI_API_KEY:-}" ]]; then
  echo "âŒ ERROR: AI provider API key required"
  echo "Set one of: ANTHROPIC_API_KEY, OPENAI_API_KEY, or GEMINI_API_KEY"
  exit 1
fi

# -----------------------
# Optional
# -----------------------
BASE_BRANCH="${BASE_BRANCH:-staging}"
FRONT_DIR="${FRONT_DIR:-frontend}"
BRANCH_PREFIX="${BRANCH_PREFIX:-ai/task}"
REVIEW_DIR="${REVIEW_DIR:-ai-review-results}"
MAX_REVIEW_ITERATIONS="${MAX_REVIEW_ITERATIONS:-3}"

# AI Provider è‡ªå‹•æ¤œå‡º
if [[ -n "${ANTHROPIC_API_KEY:-}" ]]; then
  AI_PROVIDER="anthropic"
  AI_MODEL="${AI_MODEL:-claude-3-haiku-20240307}"
elif [[ -n "${OPENAI_API_KEY:-}" ]]; then
  AI_PROVIDER="openai"
  AI_MODEL="${AI_MODEL:-gpt-4o-mini}"
elif [[ -n "${GEMINI_API_KEY:-}" ]]; then
  AI_PROVIDER="gemini"
  AI_MODEL="${AI_MODEL:-gemini-2.0-flash-exp}"
fi

# -----------------------
# Helpers
# -----------------------
log() { printf "\n[run] %s %s\n" "$(date +'%H:%M:%S')" "$*"; }
die() { printf "\n[error] %s\n" "$*" >&2; exit 1; }

log "==================================================================="
log "ğŸš€ Snapshot-based OpenCode + AI Review Workflow v2.1"
log "==================================================================="
log "Snapshot ID: $SNAPSHOT_ID"
log "Base Branch: $BASE_BRANCH"
log "AI Provider: $AI_PROVIDER ($AI_MODEL)"
log "Max Review Iterations: $MAX_REVIEW_ITERATIONS"

# -----------------------
# 1. Sandboxå¾©å…ƒï¼ˆã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰ï¼‰
# -----------------------
log "Step 1/12: Restoring from snapshot..."

# ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰èµ·å‹•ï¼ˆã“ã®å‡¦ç†ã¯Vercel Sandboxãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å´ã§å®Ÿè¡Œæ¸ˆã¿ï¼‰
# æ—¢ã«ä»¥ä¸‹ãŒæº–å‚™å®Œäº†:
# - Repository cloned at staging
# - OpenCode & GitHub CLI installed
# - npm dependencies installed
# - Git configured
# - AI Code Review CLI installed (snapshotæº–å‚™æ™‚)

log "âœ“ Sandbox restored (3 seconds)"

# -----------------------
# 2. ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
# -----------------------
WORKDIR="${WORKDIR:-/vercel/sandbox/repo}"
cd "$WORKDIR" || die "Failed to change directory to $WORKDIR"

# æ—¢å­˜ã® origin ã‹ã‚‰ owner/repo ã‚’å–å¾—ï¼ˆpush / gh ç”¨ï¼‰
REPO_SLUG=$(git config --get remote.origin.url | sed -e 's|.*github\.com[:/]||' -e 's|\.git$||')
log "Repo: $REPO_SLUG"
log "Step 2/12: Moved to workspace"

# -----------------------
# 3. ãƒ™ãƒ¼ã‚¹ãƒ–ãƒ©ãƒ³ãƒã‚’æœ€æ–°ã«ï¼ˆå¿…é ˆï¼‰
# -----------------------
log "Step 3/12: Updating base branch to latest..."

git fetch origin "$BASE_BRANCH"
git reset --hard "origin/$BASE_BRANCH"

log "âœ“ Base branch updated to latest"

# -----------------------
# 4. æ–°ã—ã„ãƒ–ãƒ©ãƒ³ãƒä½œæˆ
# -----------------------
log "Step 4/12: Creating new branch..."

TIMESTAMP=$(date +%Y%m%d-%H%M%S)
NEW_BRANCH="${BRANCH_PREFIX}-${TIMESTAMP}"

git checkout -b "$NEW_BRANCH"

log "âœ“ Branch created: $NEW_BRANCH"

# -----------------------
# 5. Planãƒ•ã‚¡ã‚¤ãƒ«é…ç½®
# -----------------------
log "Step 5/12: Setting up plan..."

mkdir -p "$FRONT_DIR/docs"
echo "$PLAN_TEXT" > "$FRONT_DIR/docs/plan.md"

log "âœ“ Plan file ready"

# -----------------------
# 6. OpenCode Authå¾©å…ƒ
# -----------------------
log "Step 6/12: Restoring OpenCode auth..."

mkdir -p ~/.local/share/opencode
echo "$OPENCODE_AUTH_JSON_B64" | base64 -d > ~/.local/share/opencode/auth.json
chmod 600 ~/.local/share/opencode/auth.json

log "âœ“ Auth restored"

# -----------------------
# Helper: OpenCodeå®Ÿè¡Œ
# -----------------------
run_opencode_implementation() {
  local task_description="$1"
  local iteration_note="${2:-}"
  
  log "Running OpenCode implementation..."
  pushd "$FRONT_DIR" >/dev/null
  
  opencode run "$task_description

$iteration_note

Project:
- Next.js app (or frontend app in this directory)
- Use existing patterns and conventions
- Dependencies are already installed (node_modules exists)

Rules:
- Do not modify files outside this directory
- Keep changes minimal and reviewable
- Do NOT run 'npm ci' or 'npm install' (already done)

Implementation Steps:
1. Read and understand the requirements
2. Implement the functionality
3. Run quality gates (detailed below)
4. Self-review your changes

CRITICAL - Quality Gates (MUST PASS):
After implementation, you MUST run these checks IN ORDER and fix all errors:

1. Format check and auto-fix:
   \`\`\`bash
   npx biome check --write .
   \`\`\`

2. Type check (MUST pass with 0 errors):
   \`\`\`bash
   npm run tsc
   \`\`\`

3. Lint check (MUST pass with 0 errors):
   \`\`\`bash
   npm run lint
   \`\`\`

If ANY check fails:
- Read the error messages carefully
- Fix the root cause (not just symptoms)
- Re-run ALL checks from step 1
- Repeat until ALL checks pass

Only after ALL checks pass with 0 errors, provide a summary of changes."
  
  popd >/dev/null
}

# -----------------------
# Helper: AIãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œ
# -----------------------
run_ai_review() {
  local review_type="${1:-comprehensive}"
  local output_suffix="${2:-}"
  
  mkdir -p "$REVIEW_DIR/docs"
  
  log "Running ${review_type} review..."
  
  local log_file="${REVIEW_DIR}/review-${review_type}${output_suffix}.log"
  
  npx @bobmatnyc/ai-code-review "$FRONT_DIR" \
    --type "$review_type" \
    --provider "$AI_PROVIDER" \
    --model "$AI_MODEL" \
    --output json \
    2>&1 | tee "$log_file" || true
  
  # ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã—ã¦ã‚³ãƒ”ãƒ¼
  if [[ -d "$FRONT_DIR/ai-review-docs" ]]; then
    cp -r "$FRONT_DIR/ai-review-docs"/* "$REVIEW_DIR/docs/" 2>/dev/null || true
    log "âœ“ Review results saved to $REVIEW_DIR/docs"
  else
    log "âš ï¸  No review output found for ${review_type}"
  fi
}

# -----------------------
# Helper: ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœåˆ†æ
# -----------------------
analyze_review_results() {
  local review_dir="$1"
  
  log "Analyzing review results..."
  
  # ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
  if [[ ! -d "$review_dir/docs" ]] || [[ -z "$(ls -A "$review_dir/docs" 2>/dev/null)" ]]; then
    log "âš ï¸  No review files found in $review_dir/docs"
    echo '{"totalIssues":0,"bySeverity":{"critical":0,"high":0,"medium":0,"low":0},"needsFix":false,"criticalIssues":[]}'
    return
  fi
  
  # analyze-review.js ã‚’ä½¿ç”¨ï¼ˆsnapshotã«å«ã¾ã‚Œã¦ã„ã‚‹æƒ³å®šï¼‰
  if [[ -f "scripts/review-tools/analyze-review.js" ]]; then
    node scripts/review-tools/analyze-review.js "$review_dir/docs" 2>/dev/null || \
      echo '{"totalIssues":0,"bySeverity":{"critical":0,"high":0,"medium":0,"low":0},"needsFix":false,"criticalIssues":[]}'
  else
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³åˆ†æ
    node <<'EOFNODE'
const fs = require('fs');
const path = require('path');

const reviewDir = process.argv[1];
const reviewFiles = fs.readdirSync(reviewDir)
  .filter(f => f.endsWith('.json') || f.endsWith('.md'))
  .map(f => path.join(reviewDir, f));

if (reviewFiles.length === 0) {
  console.log(JSON.stringify({
    totalIssues: 0,
    bySeverity: { critical: 0, high: 0, medium: 0, low: 0 },
    needsFix: false,
    criticalIssues: []
  }));
  process.exit(0);
}

const allIssues = [];
const issuesBySeverity = { critical: [], high: [], medium: [], low: [] };

reviewFiles.forEach(file => {
  try {
    const content = fs.readFileSync(file, 'utf-8');
    
    if (file.endsWith('.json')) {
      const data = JSON.parse(content);
      const issues = data.issues || data.findings || [];
      issues.forEach(issue => {
        allIssues.push(issue);
        const severity = (issue.severity || 'low').toLowerCase();
        if (issuesBySeverity[severity]) issuesBySeverity[severity].push(issue);
      });
    }
    
    if (file.endsWith('.md')) {
      const severityPattern = /\*\*Severity:\*\*\s*(Critical|High|Medium|Low)/gi;
      let match;
      while ((match = severityPattern.exec(content)) !== null) {
        const severity = match[1].toLowerCase();
        const issue = { severity, file: 'unknown', description: 'See markdown' };
        allIssues.push(issue);
        if (issuesBySeverity[severity]) issuesBySeverity[severity].push(issue);
      }
    }
  } catch (e) {
    console.error(`Failed to parse ${file}: ${e.message}`);
  }
});

const analysis = {
  totalIssues: allIssues.length,
  bySeverity: {
    critical: issuesBySeverity.critical.length,
    high: issuesBySeverity.high.length,
    medium: issuesBySeverity.medium.length,
    low: issuesBySeverity.low.length
  },
  criticalIssues: issuesBySeverity.critical.concat(issuesBySeverity.high),
  needsFix: issuesBySeverity.critical.length > 0 || issuesBySeverity.high.length > 0
};

console.log(JSON.stringify(analysis, null, 2));

if (analysis.needsFix) {
  const fixInstructions = analysis.criticalIssues.map((issue, idx) => {
    return `${idx + 1}. [${(issue.severity || 'unknown').toUpperCase()}] ${issue.file}
   Issue: ${issue.description || issue.message || 'No description'}
`;
  }).join('\n');
  
  fs.writeFileSync(
    path.join(reviewDir, 'fix-instructions.txt'),
    `Critical and High Severity Issues:\n\n${fixInstructions}`
  );
}
EOFNODE
"$review_dir/docs"
  fi
}

# -----------------------
# 7. OpenCodeåˆæœŸå®Ÿè£…
# -----------------------
log "Step 7/12: Running OpenCode for initial implementation..."

run_opencode_implementation "$PLAN_TEXT"

log "âœ“ OpenCode initial implementation completed"

# -----------------------
# 8. AIãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œï¼ˆä¸¦åˆ—ï¼‰
# -----------------------
log "Step 8/12: Running AI Code Review (parallel)..."

# å‰å›ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’ã‚¯ãƒªã‚¢
rm -rf "$REVIEW_DIR"
rm -rf "$FRONT_DIR/ai-review-docs"
mkdir -p "$REVIEW_DIR/docs"

# è¤‡æ•°ã‚¿ã‚¤ãƒ—ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä¸¦åˆ—å®Ÿè¡Œ
run_ai_review "security" &
SECURITY_PID=$!
run_ai_review "performance" &
PERFORMANCE_PID=$!
run_ai_review "comprehensive" &
COMPREHENSIVE_PID=$!

# å…¨ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†ã‚’å¾…æ©Ÿ
wait $SECURITY_PID
wait $PERFORMANCE_PID
wait $COMPREHENSIVE_PID

log "âœ“ All reviews completed"

# -----------------------
# 9. ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœåˆ†æ
# -----------------------
log "Step 9/12: Analyzing review results..."

ANALYSIS_JSON=$(analyze_review_results "$REVIEW_DIR")
echo "$ANALYSIS_JSON" > "$REVIEW_DIR/analysis.json"

# jq ãŒã‚ã‚‹å ´åˆã¯æ•´å½¢
if command -v jq &>/dev/null; then
  cat "$REVIEW_DIR/analysis.json" | jq '.'
fi

# åˆ†æçµæœã‹ã‚‰åˆ¤å®š
NEEDS_FIX=$(echo "$ANALYSIS_JSON" | grep -o '"needsFix"[[:space:]]*:[[:space:]]*true' >/dev/null && echo "true" || echo "false")
CRITICAL_COUNT=$(echo "$ANALYSIS_JSON" | grep -o '"critical"[[:space:]]*:[[:space:]]*[0-9]*' | head -1 | grep -o '[0-9]*$' || echo "0")
HIGH_COUNT=$(echo "$ANALYSIS_JSON" | grep -o '"high"[[:space:]]*:[[:space:]]*[0-9]*' | head -1 | grep -o '[0-9]*$' || echo "0")
TOTAL_ISSUES=$(echo "$ANALYSIS_JSON" | grep -o '"totalIssues"[[:space:]]*:[[:space:]]*[0-9]*' | grep -o '[0-9]*$' || echo "0")

log "Review Analysis:"
log "  - Total issues: $TOTAL_ISSUES"
log "  - Critical: $CRITICAL_COUNT"
log "  - High: $HIGH_COUNT"

# -----------------------
# 10. ä¿®æ­£ãŒå¿…è¦ãªã‚‰åå¾©
# -----------------------
CURRENT_ITERATION=0

while [[ "$NEEDS_FIX" == "true" ]] && [[ $CURRENT_ITERATION -lt $MAX_REVIEW_ITERATIONS ]]; do
  CURRENT_ITERATION=$((CURRENT_ITERATION + 1))
  
  log "Step 10/12: Issues found. Running OpenCode fix iteration $CURRENT_ITERATION..."
  
  # ä¿®æ­£æŒ‡ç¤ºã‚’èª­ã¿è¾¼ã¿
  if [[ ! -f "$REVIEW_DIR/fix-instructions.txt" ]]; then
    log "âš ï¸  No fix-instructions.txt found, skipping fix iteration"
    break
  fi
  
  FIX_INSTRUCTIONS=$(cat "$REVIEW_DIR/fix-instructions.txt")
  
  # OpenCodeã§ä¿®æ­£å®Ÿè¡Œ
  ITERATION_NOTE="ITERATION $CURRENT_ITERATION - FIXING PREVIOUS ISSUES:

The previous implementation had the following critical/high severity issues:

$FIX_INSTRUCTIONS

Please fix ALL these issues while:
- Maintaining the original functionality
- Following the same coding patterns
- Ensuring quality gates still pass
- Providing clear explanations of fixes"

  run_opencode_implementation "$PLAN_TEXT" "$ITERATION_NOTE"
  
  log "âœ“ OpenCode fix iteration $CURRENT_ITERATION completed"
  
  # å†åº¦ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œ
  log "Re-running comprehensive review..."
  rm -rf "$FRONT_DIR/ai-review-docs"
  rm -rf "$REVIEW_DIR/docs"
  
  run_ai_review "comprehensive" "-iter${CURRENT_ITERATION}"
  
  # å†åˆ†æ
  ANALYSIS_JSON=$(analyze_review_results "$REVIEW_DIR")
  echo "$ANALYSIS_JSON" > "$REVIEW_DIR/analysis-iteration${CURRENT_ITERATION}.json"
  
  NEEDS_FIX=$(echo "$ANALYSIS_JSON" | grep -o '"needsFix"[[:space:]]*:[[:space:]]*true' >/dev/null && echo "true" || echo "false")
  CRITICAL_COUNT=$(echo "$ANALYSIS_JSON" | grep -o '"critical"[[:space:]]*:[[:space:]]*[0-9]*' | head -1 | grep -o '[0-9]*$' || echo "0")
  HIGH_COUNT=$(echo "$ANALYSIS_JSON" | grep -o '"high"[[:space:]]*:[[:space:]]*[0-9]*' | head -1 | grep -o '[0-9]*$' || echo "0")
  
  log "Re-review Analysis (Iteration $CURRENT_ITERATION):"
  log "  - Critical: $CRITICAL_COUNT"
  log "  - High: $HIGH_COUNT"
  
  if [[ "$NEEDS_FIX" == "false" ]]; then
    log "âœ… All critical/high issues resolved!"
    break
  fi
done

# æœ€å¤§åå¾©å›æ•°ã«é”ã—ãŸå ´åˆ
if [[ $CURRENT_ITERATION -ge $MAX_REVIEW_ITERATIONS ]] && [[ "$NEEDS_FIX" == "true" ]]; then
  log "âš ï¸  Maximum iterations ($MAX_REVIEW_ITERATIONS) reached with unresolved issues"
  log "âš ï¸  Manual review required before PR"
fi

# -----------------------
# 11. æœ€çµ‚ãƒã‚§ãƒƒã‚¯ï¼ˆå“è³ªã‚²ãƒ¼ãƒˆï¼‰
# -----------------------
log "Step 11/12: Running final quality gates..."

pushd "$FRONT_DIR" >/dev/null

# Biome
log "Running Biome..."
npx biome check --write . 2>&1 | tail -5 || log "âš ï¸  Biome had warnings (non-fatal)"

# TypeScript
log "Running TypeScript check..."
if ! npm run tsc 2>&1 | tail -10; then
  die "TypeScript check failed"
fi

# Lint
log "Running Lint..."
if ! npm run lint 2>&1 | tail -10; then
  die "Lint check failed"
fi

popd >/dev/null
log "âœ“ All quality gates passed"

# -----------------------
# 12. ã‚³ãƒŸãƒƒãƒˆ & PRä½œæˆ
# -----------------------
log "Step 12/12: Creating PR..."

# Gitè¨­å®š
git config user.name "OpenCode Bot"
git config user.email "opencode-bot@users.noreply.github.com"

# ã‚³ãƒŸãƒƒãƒˆ
git add -A
if git diff --cached --quiet; then
  die "No changes detected. Nothing to commit."
fi

# ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
COMMIT_MSG="feat: implement task from plan

Implemented by OpenCode (snapshot workflow v2.1)

Quality gates: âœ“ Format âœ“ TypeScript âœ“ Lint
AI Review: $(if [[ "$NEEDS_FIX" == "false" ]]; then echo "âœ“ Passed"; else echo "âš ï¸ Manual review needed"; fi) ($CURRENT_ITERATION iterations)
  - Critical issues: $CRITICAL_COUNT
  - High issues: $HIGH_COUNT
  - Total issues: $TOTAL_ISSUES"

git commit -m "$COMMIT_MSG"

# PRå†…å®¹ç”Ÿæˆ
PLAN_SUMMARY=$(head -n 1 "$FRONT_DIR/docs/plan.md" | cut -c1-60)
PR_TITLE="feat: ${PLAN_SUMMARY}"

# ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
REVIEW_SUMMARY="## ğŸ¤– AI Code Review Summary

**Review Iterations:** $CURRENT_ITERATION
**Final Status:** $(if [[ "$NEEDS_FIX" == "false" ]]; then echo "âœ… Approved"; else echo "âš ï¸ Needs Manual Review"; fi)
**AI Provider:** $AI_PROVIDER ($AI_MODEL)

### Issue Breakdown
- ğŸ”´ Critical: $CRITICAL_COUNT
- ğŸŸ  High: $HIGH_COUNT
- **Total:** $TOTAL_ISSUES

### Review Types Executed
- âœ“ Security Review (authentication, SQL injection, XSS, etc.)
- âœ“ Performance Review (N+1 queries, caching, bundle size)
- âœ“ Comprehensive Review (code quality, best practices, testing)

<details>
<summary>ğŸ“Š Detailed Analysis</summary>

\`\`\`json
$ANALYSIS_JSON
\`\`\`

</details>"

PR_BODY="## ğŸ“‹ ã‚¿ã‚¹ã‚¯å†…å®¹

\`\`\`
${PLAN_TEXT}
\`\`\`

## âœ… å®Ÿè£…å®Œäº†

- OpenCodeã«ã‚ˆã‚‹è‡ªå‹•å®Ÿè£…
- AI Code Reviewå®Ÿæ–½ï¼ˆ$CURRENT_ITERATION iterationsï¼‰
- å“è³ªãƒã‚§ãƒƒã‚¯æ¸ˆã¿ (Format / TypeScript / Lint)

$REVIEW_SUMMARY

## ğŸ“ å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«

\`\`\`
$(git diff --name-status "$BASE_BRANCH"..HEAD)
\`\`\`

## ğŸ” ç¢ºèªæ–¹æ³•

\`\`\`bash
git checkout $NEW_BRANCH
cd frontend
npm run build
\`\`\`

---
Generated by Snapshot Workflow v2.1 with AI Code Review Integration
Powered by @bobmatnyc/ai-code-review"

# Push
log "Pushing branch..."
git remote set-url origin "https://${GITHUB_TOKEN}@github.com/${REPO_SLUG}.git"
if ! git push origin "$NEW_BRANCH"; then
  die "Failed to push branch"
fi
log "âœ“ Branch pushed"

# GitHub CLIèªè¨¼
log "Authenticating GitHub CLI..."
echo "$GITHUB_TOKEN" | gh auth login --with-token 2>/dev/null || true

# ãƒªãƒã‚¸ãƒˆãƒªè¨­å®š
log "Setting repository..."
gh repo set-default "$REPO_SLUG" 2>/dev/null || true

# PRä½œæˆ
log "Creating pull request..."
PR_URL=$(gh pr create \
  --repo "$REPO_SLUG" \
  --title "$PR_TITLE" \
  --body "$PR_BODY" \
  --base "$BASE_BRANCH" \
  --head "$NEW_BRANCH" 2>&1)

PR_EXIT_CODE=$?

if [[ $PR_EXIT_CODE -ne 0 ]]; then
  log "âŒ PR creation failed with exit code: $PR_EXIT_CODE"
  log "Error output: $PR_URL"
  die "Failed to create pull request"
fi

log "==================================================================="
log "âœ… PR Created Successfully with AI Review!"
log "==================================================================="
log "PR URL: $PR_URL"
log "Branch: $NEW_BRANCH -> $BASE_BRANCH"
log "Workflow: Snapshot v2.1 with AI Review"
log "Review Iterations: $CURRENT_ITERATION"
log "Final Status: $(if [[ "$NEEDS_FIX" == "false" ]]; then echo "âœ… Approved"; else echo "âš ï¸ Manual Review Needed"; fi)"
log "Total time: ${SECONDS}s"
log "==================================================================="

# ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’PRã‚³ãƒ¡ãƒ³ãƒˆã«è¿½åŠ 
if [[ -f "$REVIEW_DIR/analysis.json" ]]; then
  log "Adding review analysis as PR comment..."
  
  gh pr comment "$PR_URL" --body "## ğŸ“Š Detailed AI Review Analysis

<details>
<summary>Click to expand full analysis</summary>

\`\`\`json
$(cat "$REVIEW_DIR/analysis.json")
\`\`\`

</details>

### Review Artifacts
- Analysis: \`$REVIEW_DIR/analysis.json\`
- Logs: \`$REVIEW_DIR/*.log\`

**AI Provider:** $AI_PROVIDER ($AI_MODEL)" 2>/dev/null || log "âš ï¸  Failed to add PR comment"
fi

echo "$PR_URL"
log "âœ“ Workflow completed successfully"
